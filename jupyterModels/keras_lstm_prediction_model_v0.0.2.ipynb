{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6123b88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock Price Predictiong Using Python & Machine Learning with LSTM model (Long Short Term Memory)\n",
    "pip install pandas_datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64282461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import math                                    # mathematical functions        https://docs.python.org/3/library/math.html\n",
    "import pandas_datareader as web                # data reader for panda         https://pandas-datareader.readthedocs.io/en/latest/\n",
    "import numpy as np                             # numerical data in python      https://numpy.org/doc/stable/user/absolute_beginners.html\n",
    "import pandas as pd                            # data analysis toolkit         https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt                # plotting data in figures      https://matplotlib.org/2.0.2/users/pyplot_tutorial.html\n",
    "from sklearn.preprocessing import MinMaxScaler # raw data utility functions    https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "from keras import metrics as metrics\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential            # input output sequence of data https://www.tensorflow.org/guide/keras/sequential_model\n",
    "from datetime import datetime, timedelta       # for manipulating dates        https://docs.python.org/3/library/datetime.html\n",
    "from keras.layers import Dense, LSTM, Dropout  # layers for neural network     https://keras.io/api/layers/\n",
    "plt.style.use('fivethirtyeight')               # plot style                    https://matplotlib.org/3.1.0/gallery/style_sheets/fivethirtyeight.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45486b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock attributes\n",
    "stock = 'GOOGL'\n",
    "source = 'yahoo'\n",
    "today = datetime.now() # todays date (YYYY-MM-DD HH:MM:SS)\n",
    "years = 20            # years back to start from when grabbing stocks, i.e 10 years = 2020-10 = 2010\n",
    "startYear = today-timedelta(days=365*years)\n",
    "\n",
    "# Get stock data using pandas data reader\n",
    "df = web.DataReader(stock, data_source=source, start=startYear, end=today)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc781c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows and columns from the dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dfbc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show closing price history\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Closing Price History, source: ' + source)\n",
    "plt.plot(df['Close'])\n",
    "plt.xlabel(stock + ' stock data', fontsize=18)\n",
    "plt.ylabel('Close Price USD ($)', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf508f6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create new dataframe with 'Close' column\n",
    "data_target = df.filter(['Close'])\n",
    "\n",
    "# Covert dataframe into a numpy array with a 1 day delay\n",
    "dataset = data_target.shift(-1, fill_value=0).values\n",
    "\n",
    "# Get the number of rows to train the model on, using 80% of the data\n",
    "training_data_len = math.ceil(len(dataset) * .8)\n",
    "\n",
    "# Scale data between 0 and 1 to avoid the bias using normalization\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d565d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset\n",
    "# Create the scaled training dataset\n",
    "train_data = scaled_data[0:training_data_len , :]\n",
    "\n",
    "# Split data into x_train and y_train datasets\n",
    "time_interval = int(len(dataset)*0.05) # amount of steps to train on, I.E the amount of data the LSTM uses per \"step\" ex: [0,1,2....60] if time_interval = 10 first LSTM step will be 0-9 and predict 10, second step woule be 1-10 and predict 11. =\n",
    "x_train = []   # past x days, using previous example this would be 0-9\n",
    "y_train = []   # predicted target value.              this would be predicted value for 10\n",
    "\n",
    "# loop for the last x days\n",
    "for i in range(time_interval, len(train_data)):\n",
    "    x_train.append(train_data[i-time_interval:i, 0]) # append closingprice for i day\n",
    "    y_train.append(train_data[i, 0])             # append predicted value\n",
    "    \n",
    "# Convert x_train and y_train to numpy arrays to use in LSTM model\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# Reshape data from 2D to 3D\n",
    "# LSTM network needs 3D input (number of samples, timesteps and features)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fe8dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "# # Run first layer with train data as input, 250 nodes, drop 20% when done, only return last output\n",
    "# model.add(LSTM(250, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# # Run a second layer with 250 nodes, drop 10% \n",
    "# model.add(LSTM(250, return_sequences=True))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# Run a third layer with 50 nodes, drop 10% when done return whole output\n",
    "model.add(LSTM(500, return_sequences=False))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# Run a fourth layer with 25 nodes and 10% dropout\n",
    "model.add(Dense(25))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(units = 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38a446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for calculating RMSE used for loss in model.compile\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556ab420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "# Optimizer is to improve upon the loss function https://keras.io/api/optimizers/adam/\n",
    "# loss function is used to measure how good the model did on training in terms of RMSE\n",
    "# Metrics is used to evaluate the accuracy of predicitons (currently does not work)\n",
    "model.compile(optimizer='adam', loss=root_mean_squared_error, metrics=[\n",
    "        metrics.MeanSquaredError(name=\"MSE\"),\n",
    "        metrics.MeanAbsoluteError(name=\"MAE\"),\n",
    "        metrics.MeanSquaredLogarithmicError(name=\"MSLE\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90016de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "# Batch size is the total number of training examples present in a single batch.\n",
    "# Epoch is the number of iterations when an entire dataset is passed forward and backward through a neural network\n",
    "model.fit(x_train, y_train, batch_size=48, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65a75fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create testing dataset\n",
    "# Create a new array containing scaled values\n",
    "test_data = scaled_data[training_data_len - time_interval: :]\n",
    "\n",
    "# Create the data sets x_test and y_test\n",
    "x_test = [] # past x days\n",
    "y_test = dataset[training_data_len:, :] # predicted value\n",
    "\n",
    "# loop for the last x days\n",
    "for i in range(time_interval, len(test_data)):\n",
    "    x_test.append(test_data[i-time_interval:i, 0]) # append closing price for i day\n",
    "    \n",
    "# Convert data into a numpy array to use in LSTM model\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "# Reshape data from 2D to 3D\n",
    "# LSTM network needs 3D input (number of samples, timesteps and features)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e15593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model predicted unscaled closingprice value\n",
    "predictions = model.predict(x_test)\n",
    "predictions = scaler.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7103228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the accuracy of our predictions against the actual values within a given percentile\n",
    "def accuracy_calc(percentage):\n",
    "    actual = y_test\n",
    "    ok_accuracy = 0\n",
    "    total = actual.size\n",
    "    threshold = (100 - percentage) / 100\n",
    "    lower = 1-threshold\n",
    "    upper = 1+threshold\n",
    "\n",
    "    for i in range(total):\n",
    "        cur_act = actual[i]\n",
    "        cur_pred = predictions[i]\n",
    "        if cur_act >= cur_pred*lower and cur_act <= cur_pred*upper:\n",
    "            ok_accuracy +=1\n",
    "    acc = ok_accuracy/total\n",
    "    print(f\"Percentage of predicted values within {percentage}% margin of actual: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460b561c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"RMSE: \", root_mean_squared_error(y_test, predictions))\n",
    "accuracy_calc(50)\n",
    "accuracy_calc(60)\n",
    "accuracy_calc(70)\n",
    "accuracy_calc(80)\n",
    "accuracy_calc(90)\n",
    "accuracy_calc(95)\n",
    "accuracy_calc(99)\n",
    "\n",
    "# Evaluate model \n",
    "model.evaluate(x_test, y_test, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad20f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data\n",
    "train = data_target[:training_data_len]\n",
    "valid = data_target[training_data_len:]\n",
    "valid['Predictions'] = predictions\n",
    "\n",
    "# Visualize data\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Predictions VS Actual')\n",
    "plt.xlabel(stock + ' stock data', fontsize=18)\n",
    "plt.ylabel('Closing Price USD ($)', fontsize=18)\n",
    "plt.plot(valid[['Close', 'Predictions']])\n",
    "plt.legend(['Val', 'Predictions'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a413fcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all valid and predicted prices\n",
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f30f02c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8316b773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d04f02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
